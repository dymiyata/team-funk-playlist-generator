{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c56a9ca-c672-4d8d-a014-4b495f36d8e7",
   "metadata": {},
   "source": [
    "## Load packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b2da703-530a-4859-a17f-7816f564c94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove hashtag and run code below to install packages\n",
    "\n",
    "#!pip install -U sentence-transformers\n",
    "#!pip install --user annoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c2bfaa2-2b3b-4567-b22d-64bf89c074aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import copy\n",
    "import time\n",
    "from annoy import AnnoyIndex\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2304a7f1-d7c5-4778-8f08-f150831880ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# n is the number of json files we wish to read (max is 1000)\n",
    "n = 5\n",
    "\n",
    "for i in range(n):\n",
    "    # create the file_name string in order to read in file\n",
    "    file_name = 'spotify_million_playlist_dataset/data/mpd.slice.' \\\n",
    "        + str(i*1000 ) \\\n",
    "        + '-' + str(i*1000+999) + '.json'\n",
    "\n",
    "    # Uncomment the following line to show progress\n",
    "    #print(file_name)\n",
    "\n",
    "    # open the file and store its contents in file_contents\n",
    "    with open(file_name) as user_file:\n",
    "        file_contents = user_file.read()\n",
    "\n",
    "    # we only care about the \"playlists\" part of this dictionary\n",
    "    # save the list of playlists in playlist_list\n",
    "    parsed_json = json.loads(file_contents)\n",
    "    playlist_list = parsed_json[\"playlists\"]\n",
    "\n",
    "\n",
    "    # create dataframe if it's first playlist, otherwise append info to existing dataframe\n",
    "    # the record_path argument tells the json_normalize function how to flatten the data\n",
    "    # the meta argument tells the json_nomralize function what meta data to keep\n",
    "    if i == 0:\n",
    "        data = pd.json_normalize(\n",
    "            playlist_list,\n",
    "            record_path=\"tracks\",\n",
    "            meta=[\"name\", \"collaborative\", \"pid\", \"num_followers\", \"num_edits\"]\n",
    "        )\n",
    "    else:\n",
    "        data = pd.concat(\n",
    "            [\n",
    "                data,\n",
    "                pd.json_normalize(\n",
    "                    playlist_list,\n",
    "                    record_path=\"tracks\",\n",
    "                    meta=[\"name\", \"collaborative\", \"pid\", \"num_followers\", \"num_edits\"]\n",
    "                )\n",
    "            ],\n",
    "            ignore_index = True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8177d43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make copy of data to prevent any funny business\n",
    "df = data.copy()\n",
    "## drop duplicate pid as well\n",
    "df = df.drop_duplicates(subset = ['pid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f60778c",
   "metadata": {},
   "source": [
    "# Generate playlist vectors using sentence transformers and load into annoy index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b8b52f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.310036420822144\n"
     ]
    }
   ],
   "source": [
    "#Building the database here\n",
    "#make vectors using sentence transformer\n",
    "#load vectors into annoy index along with pid\n",
    "t0 = time.time()\n",
    "\n",
    "#dimension of vectors the model uses\n",
    "f = model.get_sentence_embedding_dimension()\n",
    "\n",
    "#build database we will load vectors in\n",
    "#angular means we are using cosine similarty metric\n",
    "t = AnnoyIndex(f , 'angular')\n",
    "\n",
    "for (_,name,pid) in df[['name', 'pid']].itertuples(name=None):\n",
    "    v = model.encode(name.lower().strip() )\n",
    "    t.add_item(pid , v)\n",
    "\n",
    "#number of trees for search\n",
    "t.build(100)\n",
    "t.save('playlist_vectors.ann')\n",
    "\n",
    "t1 =time.time()\n",
    "\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daf1e40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
