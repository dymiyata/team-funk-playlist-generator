{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/dymiyata/erdos2023_million_playlist_challenge/blob/master/matrix_factorization/matrix_factorization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JZtDAeafHyXf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import copy\n",
    "import random\n",
    "from numba import njit\n",
    "\n",
    "import sqlalchemy as db\n",
    "\n",
    "from time import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions\n",
    "\n",
    "Define a function to load the SQL database into R_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_R_list_sql(conn, pid_limit=None, progress=5.):\n",
    "    if pid_limit is None:\n",
    "        # Get number of pairings\n",
    "        results = conn.execute(db.text(\"SELECT COUNT(*) FROM pairings\"))\n",
    "        N = results.fetchall()[0][0]\n",
    "        \n",
    "        # Get columns one by one\n",
    "        results = conn.execute(db.text(\"SELECT pid, tid FROM pairings\"))\n",
    "    else:\n",
    "        # Get number of pairings\n",
    "        results = conn.execute(db.text(f\"SELECT COUNT(*) FROM pairings WHERE pid<{pid_limit}\"))\n",
    "        N = results.fetchall()[0][0]\n",
    "        \n",
    "        # Get columns one by one\n",
    "        results = conn.execute(db.text(f\"SELECT pid, tid FROM pairings WHERE pid<{pid_limit}\"))\n",
    "    \n",
    "    R_list = np.empty((N,2))\n",
    "    for i in range(N):\n",
    "        \n",
    "        if not progress is None:\n",
    "            # Show progress\n",
    "            if i % np.round(N*progress/100) == 0:\n",
    "                print('{:.2f}%'.format(i/N*100))\n",
    "        \n",
    "        row = results.fetchone()\n",
    "        R_list[i,0] = int(row[0])\n",
    "        R_list[i,1] = int(row[1])\n",
    "    \n",
    "    return R_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions for running gradient descent and computing the error function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use gradient descent to minimize MSE (with l2 regularization)\n",
    "def update_params_loop(R_list, P, Q, alpha, llambda):\n",
    "    newP = P\n",
    "    newQ = Q\n",
    "    m , f = np.shape(P)\n",
    "    n = np.shape(Q)[0]\n",
    "\n",
    "    for u,i in R_list:\n",
    "        newP[u,:] -= alpha * 2 * (P[u,:] @ Q[i,:] - 1) * Q[i,:]\n",
    "        newQ[i,:] -= alpha * 2 * (P[u,:] @ Q[i,:] - 1) * P[u,:]\n",
    "    for u in range(m):\n",
    "        newP[u,:] -= alpha * 2 * llambda * P[u,:]\n",
    "    for i in range(n):\n",
    "        newQ[i,:] -= alpha * 2 * llambda * Q[i,:]\n",
    "    return (newP, newQ)\n",
    "\n",
    "# use gradient descent with where R_list has triples (u,i,score)\n",
    "def update_params_loop_score(R_list, P, Q, alpha, llambda):\n",
    "    newP = P\n",
    "    newQ = Q\n",
    "    m , f = np.shape(P)\n",
    "    n = np.shape(Q)[0]\n",
    "\n",
    "    for u,i, score in R_list:\n",
    "        newP[u,:] -= alpha * 2 * (P[u,:] @ Q[i,:] - score) * Q[i,:]\n",
    "        newQ[i,:] -= alpha * 2 * (P[u,:] @ Q[i,:] - score) * P[u,:]\n",
    "    for u in range(m):\n",
    "        newP[u,:] -= alpha * 2 * llambda * P[u,:]\n",
    "    for i in range(n):\n",
    "        newQ[i,:] -= alpha * 2 * llambda * Q[i,:]\n",
    "    return (newP, newQ)\n",
    "\n",
    "# Run an epoch of gradient descent where the iterations parameter is the number of iterations.\n",
    "@njit\n",
    "def run_epoch(R_array, P, Q, alpha, llambda, iterations):\n",
    "    oldP = P.copy()\n",
    "    oldQ = Q.copy()\n",
    "    f = np.shape(P)[1]\n",
    "\n",
    "    for iter in range(iterations):\n",
    "        newP = oldP.copy()\n",
    "        newQ = oldQ.copy()\n",
    "        for u,i in R_array:\n",
    "            dotprod = 0\n",
    "            for feature in range(f):\n",
    "                dotprod += oldP[u,feature] * oldQ[i,feature]\n",
    "            error = dotprod - 1\n",
    "\n",
    "            for feature in range(f):\n",
    "                pf = oldP[u,feature]\n",
    "                qf = oldQ[i,feature]\n",
    "                newP[u,feature] -= alpha * (error * qf + llambda * pf) \n",
    "                newQ[i,feature] -= alpha * (error * pf + llambda * qf)\n",
    "        oldP = newP\n",
    "        oldQ = newQ\n",
    "    return newP, newQ\n",
    "\n",
    "\n",
    "#runs the gradient descent loop in batches\n",
    "def gd_batch(R_list, P, Q, alpha, llambda, batch_num, iterations, R = None, verbose=False):\n",
    "    #make copies of P and Q\n",
    "    P_current = P.copy()\n",
    "    Q_current = Q.copy()\n",
    "\n",
    "    #shuffle R_list\n",
    "    #divide R_list into batch_num subsets\n",
    "    random.shuffle(R_list)\n",
    "    batch_size = int(np.ceil(len(R_list)/batch_num))\n",
    "    R_batch = [R_list[i:i+batch_size] for i in range(0,len(R_list), batch_size) ]\n",
    "\n",
    "    #loop over total iterations\n",
    "    for i in range(iterations):\n",
    "        #if verbose == true print out error function\n",
    "        if verbose:\n",
    "            print(f'Step {i*batch_num}: Error function={error_function(R_list,R , P_current, Q_current)}')\n",
    "        #loop over batch_num\n",
    "        for batch in R_batch:\n",
    "            #run update_param_loop on batch\n",
    "            P_current , Q_current = update_params_loop(batch, P_current, Q_current, alpha, llambda)\n",
    "\n",
    "    return (P_current , Q_current)\n",
    "\n",
    "#error function without l2 normalization factor\n",
    "def error_function( R_list,R, P , Q ):\n",
    "    result = 0\n",
    "    #sum over R_list\n",
    "    for row, col in R_list:\n",
    "        result = result + (R[row,col] - P[row,:]@Q[col,:])**2\n",
    "\n",
    "    return result\n",
    "\n",
    "@njit\n",
    "def error_function_l2( R_list, P , Q, llambda):\n",
    "    result = 0\n",
    "    #sum over R_list\n",
    "    for row, col in R_list:\n",
    "        result = result + (1 - P[row,:]@Q[col,:])**2\n",
    "    result += llambda * (np.linalg.norm(P)**2 + np.linalg.norm(Q)**2)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function for obtaining the playlist vector that minimizes the cost function for a fixed $Q$ from a list of track id's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_user_vec(tid_list, Q, llambda):\n",
    "    Y = Q[tid_list,:]\n",
    "    f = np.shape(Q)[1]\n",
    "    d = len(tid_list)\n",
    "    vec = np.linalg.inv(np.transpose(Y) @ Y + llambda * np.identity(f)) @ np.transpose(Y) @ np.ones((d,1))\n",
    "    return np.transpose(vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mRfZHGotHyXh"
   },
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next two cells read in data and creates the list of data points.  Ideally this will be done by querying the SQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = \"sqlite:///../spotify_sql_with_tid_0.db\"\n",
    "engine = db.create_engine(db_path)\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00%\n",
      "10.00%\n",
      "20.00%\n",
      "30.00%\n",
      "40.00%\n",
      "50.00%\n",
      "60.00%\n",
      "70.00%\n",
      "80.00%\n",
      "90.00%\n",
      "100.00%\n",
      "8.041 sec\n",
      "0.134 minutes\n",
      "\n",
      "We have 10000 playlists\n"
     ]
    }
   ],
   "source": [
    "time_0 = time()\n",
    "R_list = make_R_list_sql(conn, pid_limit=10000, progress=10)\n",
    "time_end = time()\n",
    "\n",
    "print('{:.3f} sec'.format(time_end-time_0))\n",
    "print('{:.3f} minutes'.format((time_end-time_0)/60))\n",
    "print()\n",
    "\n",
    "num_playlists = len(np.unique(R_list[:,0]))\n",
    "print(f'We have {num_playlists} playlists')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of the total database to reserve for validation and testing\n",
    "val_size_abs = 0.15\n",
    "test_size    = 0.15\n",
    "shuffle = True\n",
    "\n",
    "# Note: the first pid_train contains (1-test_size) percent of the data.\n",
    "# We need to use val_size so that val_size*(1-test_size) = val_size_abs.\n",
    "val_size = val_size_abs/(1-test_size)\n",
    "pid_train, pid_test = train_test_split(np.arange(num_playlists), test_size=test_size,\n",
    "                                       shuffle=shuffle, random_state=11)\n",
    "pid_train, pid_val  = train_test_split(pid_train, test_size=val_size,\n",
    "                                       shuffle=shuffle, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_list_train = R_list[ np.isin(R_list[:,0], pid_train), :]\n",
    "R_list_val   = R_list[ np.isin(R_list[:,0], pid_val),   :]\n",
    "R_list_test  = R_list[ np.isin(R_list[:,0], pid_test),  :]\n",
    "\n",
    "# Store the track id of songs in the train/val/test sets\n",
    "tid_train = list(np.unique( R_list_train[:,1] ))\n",
    "tid_val   = list(np.unique( R_list_val[:,1]   ))\n",
    "tid_test  = list(np.unique( R_list_test[:,1]  ))\n",
    "\n",
    "num_songs = len(tid_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of training the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we specify the number of features and create matrices $P$ and $Q$ whose entries are randomly taken from a normal distribution with $\\mu = 0$ and $\\sigma = 0.1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 10 # number of latent features\n",
    "# num_songs = max(reverse_track_dict.keys()) + 1\n",
    "num_songs = len(tid_train)\n",
    "num_playlists = len(pid_train)\n",
    "\n",
    "# initialize random values for matrices P and Q. Entries are between -1 and 1\n",
    "P = np.random.normal(0, 0.1, (num_playlists, f))\n",
    "Q = np.random.normal(0, 0.1, (num_songs, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, we run the gradient descent algorithm and store the resulting matrices in P_trained and Q_trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b_nyoRWcHyXi"
   },
   "outputs": [],
   "source": [
    "# Run gradient descent algorithm with alpha = 0.001, llambda = 0.005 for 100 iterations\n",
    "P_trained, Q_trained = run_epoch(R_list_train, P, Q, 0.001, 0.005, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of computing error on non-training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to demonstrate how to compute error for a new collection of playlists, let's first read in an extra json file's worth of data (I could've just read in the single extra file instead of all original files again but I was too lazy to change the read_data function). Again this step should utilize the SQL database.\n",
    "\n",
    "**Note:** I changed R_list_new into R_list_test during the train-val-test split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our fixed Q, given a list of (new) playlist ids, we can compute the P matrix that minimizes the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS FUNCTION, (as well as new_user_vec) CAN AND SHOULD BE OPTIMIZED TO USE numba.  \n",
    "# For the sake of time, I'll leave it as is for now\n",
    "# If we can avoid using lists (like tid_list), then things will be numba compatible. \n",
    "def make_Pval(new_pids, R_list_new, Q, llambda, tid_known=tid_train):\n",
    "    num_songs , f = np.shape(Q)\n",
    "    P_val = np.zeros((len(new_pids), f))\n",
    "    count = 0 # keeps track of where in pid_list we are\n",
    "    \n",
    "    # Remove tracks that we don't recognize\n",
    "    R_list_new = R_list_new[ np.isin(R_list_new[:,1], tid_known), : ]\n",
    "    \n",
    "    for pid in new_pids:\n",
    "        # create list of tracks in the playlist\n",
    "        # Remember: R_list_new has two columns: 0 is pid, 1 is tid\n",
    "        tid_list = R_list_new[ R_list_new[:,0]==pid, 1]\n",
    "        \n",
    "        # With repetition\n",
    "        # tid_list = list(tid_list)\n",
    "        # tid_list = [tid for tid in tid_list if tid in tid_known]\n",
    "        \n",
    "        # Without repetition\n",
    "        # tid_list = list( set(tid_list).intersection(tid_known) )\n",
    "\n",
    "        # x is the row of Pval corresponding to this pid\n",
    "        x = new_user_vec(tid_list, Q_trained, llambda)\n",
    "        for feature in range(f):\n",
    "            P_val[count, feature] = x[0,feature]\n",
    "        count += 1\n",
    "        \n",
    "    return P_val\n",
    "\n",
    "Pval = make_Pval(pid_test, R_list_test, Q_trained, 0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compute the error function on this set. Note, we can't use the function defined at the top of this document because now the pid does not correspond to the index of the column of Pval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_error(R_list_new, pid_list, Pval, Q, llambda, tid_known=tid_train):\n",
    "    _, f = np.shape(Q)\n",
    "    result = 0\n",
    "    \n",
    "    # Remove tracks that we don't recognize\n",
    "    R_list_new = R_list_new[ np.isin(R_list_new[:,1], tid_known), : ]\n",
    "    \n",
    "    for pid, tid in R_list_new:\n",
    "        result += (1 - Pval[pid_list.index(pid), :] @ Q[tid, :])\n",
    "    \n",
    "    result += llambda * (np.linalg.norm(Pval)**2)\n",
    "    return result\n",
    "\n",
    "val_error(R_list_test, pid_test, Pval, Q_trained, 0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find best hyperparameters using grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypingError",
     "evalue": "Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1mNo implementation of function Function(<built-in function getitem>) found for signature:\n \n >>> getitem(array(float64, 2d, C), Tuple(float64, int64))\n \nThere are 22 candidate implementations:\n\u001b[1m      - Of which 20 did not match due to:\n      Overload of function 'getitem': File: <numerous>: Line N/A.\n        With argument(s): '(array(float64, 2d, C), Tuple(float64, int64))':\u001b[0m\n\u001b[1m       No match.\u001b[0m\n\u001b[1m      - Of which 2 did not match due to:\n      Overload in function 'GetItemBuffer.generic': File: numba/core/typing/arraydecl.py: Line 209.\n        With argument(s): '(array(float64, 2d, C), Tuple(float64, int64))':\u001b[0m\n\u001b[1m       Rejected as the implementation raised a specific error:\n         NumbaTypeError: \u001b[1mUnsupported array index type float64 in Tuple(float64, int64)\u001b[0m\u001b[0m\n  raised from /home/MRGomez/anaconda3/envs/audio/lib/python3.11/site-packages/numba/core/typing/arraydecl.py:102\n\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of intrinsic-call at /tmp/ipykernel_8288/2744927450.py (46)\u001b[0m\n\u001b[1m\nFile \"../../../../../../../tmp/ipykernel_8288/2744927450.py\", line 46:\u001b[0m\n\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m Q_initial \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, (num_songs, f))\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Obtain P, Q with the chosen hyperparameters\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m P_trained, Q_trained \u001b[38;5;241m=\u001b[39m run_epoch(R_list_train, P\u001b[38;5;241m=\u001b[39mP_initial, Q\u001b[38;5;241m=\u001b[39mQ_initial, alpha\u001b[38;5;241m=\u001b[39malpha, llambda\u001b[38;5;241m=\u001b[39mllambda, iterations\u001b[38;5;241m=\u001b[39mNUM_ITERATIONS)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Check results against the validation set\u001b[39;00m\n\u001b[1;32m     33\u001b[0m P_val \u001b[38;5;241m=\u001b[39m make_Pval(pid_val, R_val, Q_trained, llambda)\n",
      "File \u001b[0;32m~/anaconda3/envs/audio/lib/python3.11/site-packages/numba/core/dispatcher.py:468\u001b[0m, in \u001b[0;36m_DispatcherBase._compile_for_args\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m    464\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;241m.\u001b[39mrstrip()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mThis error may have been caused \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    465\u001b[0m                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby the following argument(s):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00margs_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    466\u001b[0m         e\u001b[38;5;241m.\u001b[39mpatch_message(msg)\n\u001b[0;32m--> 468\u001b[0m     error_rewrite(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtyping\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mUnsupportedError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;66;03m# Something unsupported is present in the user code, add help info\u001b[39;00m\n\u001b[1;32m    471\u001b[0m     error_rewrite(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munsupported_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/audio/lib/python3.11/site-packages/numba/core/dispatcher.py:409\u001b[0m, in \u001b[0;36m_DispatcherBase._compile_for_args.<locals>.error_rewrite\u001b[0;34m(e, issue_type)\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mTypingError\u001b[0m: Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1mNo implementation of function Function(<built-in function getitem>) found for signature:\n \n >>> getitem(array(float64, 2d, C), Tuple(float64, int64))\n \nThere are 22 candidate implementations:\n\u001b[1m      - Of which 20 did not match due to:\n      Overload of function 'getitem': File: <numerous>: Line N/A.\n        With argument(s): '(array(float64, 2d, C), Tuple(float64, int64))':\u001b[0m\n\u001b[1m       No match.\u001b[0m\n\u001b[1m      - Of which 2 did not match due to:\n      Overload in function 'GetItemBuffer.generic': File: numba/core/typing/arraydecl.py: Line 209.\n        With argument(s): '(array(float64, 2d, C), Tuple(float64, int64))':\u001b[0m\n\u001b[1m       Rejected as the implementation raised a specific error:\n         NumbaTypeError: \u001b[1mUnsupported array index type float64 in Tuple(float64, int64)\u001b[0m\u001b[0m\n  raised from /home/MRGomez/anaconda3/envs/audio/lib/python3.11/site-packages/numba/core/typing/arraydecl.py:102\n\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of intrinsic-call at /tmp/ipykernel_8288/2744927450.py (46)\u001b[0m\n\u001b[1m\nFile \"../../../../../../../tmp/ipykernel_8288/2744927450.py\", line 46:\u001b[0m\n\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning using grid search\n",
    "# Specify the number of latent features (f), learning rate (alpha), and regularization parameter (llambda)\n",
    "f_values = [5, 10, 15]\n",
    "alpha_values = [0.001, 0.01, 0.1]\n",
    "llambda_values = [0.001, 0.01, 0.1]\n",
    "\n",
    "NUM_ITERATIONS = 100\n",
    "\n",
    "nF = len(f_values)\n",
    "nA = len(alpha_values)\n",
    "nL = len(llambda_values)\n",
    "\n",
    "time_start = time()\n",
    "best_error = float('inf')\n",
    "best_hyperparameters = None\n",
    "for idf in range(nF):\n",
    "    f = f_values[idf]\n",
    "    for ida in range(nA):\n",
    "        alpha = alpha_values[ida]\n",
    "        for idl in range(nL):\n",
    "            llambda = llambda_values[idl]\n",
    "            \n",
    "            time_0 = time()\n",
    "            \n",
    "            # Initialize random values\n",
    "            P_initial = np.random.normal(0, 0.1, (num_playlists, f))\n",
    "            Q_initial = np.random.normal(0, 0.1, (num_songs, f))\n",
    "            \n",
    "            # Obtain P, Q with the chosen hyperparameters\n",
    "            P_trained, Q_trained = run_epoch(R_list_train, P=P_initial, Q=Q_initial, alpha=alpha, llambda=llambda, iterations=NUM_ITERATIONS)\n",
    "            \n",
    "            # Check results against the validation set\n",
    "            P_val = make_Pval(pid_val, R_val, Q_trained, llambda)\n",
    "            current_error = error_function_l2(R_val, P_val, Q_trained, llambda)\n",
    "            \n",
    "            # Store the best hyperparameters\n",
    "            if current_error < best_error:\n",
    "                best_error = current_error\n",
    "                best_hyperparameters = {'f': f, 'alpha': alpha, 'llambda': llambda}\n",
    "            \n",
    "            time_t = time()\n",
    "            print(f'({idf},{ida},{idl})/({nF},{nA},{nL}):')\n",
    "            print('{:.3f} sec'.format(time_t-time_0))\n",
    "            print('{:.3f} minutes'.format((time_t-time_0)/60))\n",
    "            print()\n",
    "\n",
    "time_end = time()\n",
    "print('Total time:')\n",
    "print('{:.3f} sec'.format(time_end-time_start))\n",
    "print('{:.3f} minutes'.format((time_end-time_start)/60))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypingError",
     "evalue": "Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1mNo implementation of function Function(<built-in function getitem>) found for signature:\n \n >>> getitem(array(float64, 2d, C), Tuple(float64, int64))\n \nThere are 22 candidate implementations:\n\u001b[1m      - Of which 20 did not match due to:\n      Overload of function 'getitem': File: <numerous>: Line N/A.\n        With argument(s): '(array(float64, 2d, C), Tuple(float64, int64))':\u001b[0m\n\u001b[1m       No match.\u001b[0m\n\u001b[1m      - Of which 2 did not match due to:\n      Overload in function 'GetItemBuffer.generic': File: numba/core/typing/arraydecl.py: Line 209.\n        With argument(s): '(array(float64, 2d, C), Tuple(float64, int64))':\u001b[0m\n\u001b[1m       Rejected as the implementation raised a specific error:\n         NumbaTypeError: \u001b[1mUnsupported array index type float64 in Tuple(float64, int64)\u001b[0m\u001b[0m\n  raised from /home/MRGomez/anaconda3/envs/audio/lib/python3.11/site-packages/numba/core/typing/arraydecl.py:102\n\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of intrinsic-call at /tmp/ipykernel_8288/2744927450.py (46)\u001b[0m\n\u001b[1m\nFile \"../../../../../../../tmp/ipykernel_8288/2744927450.py\", line 46:\u001b[0m\n\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m Q_initial \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, (num_songs, f))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Obtain P, Q with the chosen hyperparameters\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m P_trained, Q_trained \u001b[38;5;241m=\u001b[39m run_epoch(R_list_train, P\u001b[38;5;241m=\u001b[39mP_initial, Q\u001b[38;5;241m=\u001b[39mQ_initial, alpha\u001b[38;5;241m=\u001b[39malpha, llambda\u001b[38;5;241m=\u001b[39mllambda, iterations\u001b[38;5;241m=\u001b[39mNUM_ITERATIONS)\n",
      "File \u001b[0;32m~/anaconda3/envs/audio/lib/python3.11/site-packages/numba/core/dispatcher.py:468\u001b[0m, in \u001b[0;36m_DispatcherBase._compile_for_args\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m    464\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;241m.\u001b[39mrstrip()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mThis error may have been caused \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    465\u001b[0m                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby the following argument(s):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00margs_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    466\u001b[0m         e\u001b[38;5;241m.\u001b[39mpatch_message(msg)\n\u001b[0;32m--> 468\u001b[0m     error_rewrite(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtyping\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mUnsupportedError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;66;03m# Something unsupported is present in the user code, add help info\u001b[39;00m\n\u001b[1;32m    471\u001b[0m     error_rewrite(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munsupported_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/audio/lib/python3.11/site-packages/numba/core/dispatcher.py:409\u001b[0m, in \u001b[0;36m_DispatcherBase._compile_for_args.<locals>.error_rewrite\u001b[0;34m(e, issue_type)\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mTypingError\u001b[0m: Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1mNo implementation of function Function(<built-in function getitem>) found for signature:\n \n >>> getitem(array(float64, 2d, C), Tuple(float64, int64))\n \nThere are 22 candidate implementations:\n\u001b[1m      - Of which 20 did not match due to:\n      Overload of function 'getitem': File: <numerous>: Line N/A.\n        With argument(s): '(array(float64, 2d, C), Tuple(float64, int64))':\u001b[0m\n\u001b[1m       No match.\u001b[0m\n\u001b[1m      - Of which 2 did not match due to:\n      Overload in function 'GetItemBuffer.generic': File: numba/core/typing/arraydecl.py: Line 209.\n        With argument(s): '(array(float64, 2d, C), Tuple(float64, int64))':\u001b[0m\n\u001b[1m       Rejected as the implementation raised a specific error:\n         NumbaTypeError: \u001b[1mUnsupported array index type float64 in Tuple(float64, int64)\u001b[0m\u001b[0m\n  raised from /home/MRGomez/anaconda3/envs/audio/lib/python3.11/site-packages/numba/core/typing/arraydecl.py:102\n\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of intrinsic-call at /tmp/ipykernel_8288/2744927450.py (46)\u001b[0m\n\u001b[1m\nFile \"../../../../../../../tmp/ipykernel_8288/2744927450.py\", line 46:\u001b[0m\n\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Initialize random values\n",
    "P_initial = np.random.normal(0, 0.1, (num_playlists, f))\n",
    "Q_initial = np.random.normal(0, 0.1, (num_songs, f))\n",
    "\n",
    "# Obtain P, Q with the chosen hyperparameters\n",
    "P_trained, Q_trained = run_epoch(R_list_train, P=P_initial, Q=Q_initial, alpha=alpha, llambda=llambda, iterations=NUM_ITERATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
