{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "177d8b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from annoy import AnnoyIndex\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cf462012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n is the number of json files we wish to read (max is 1000)\n",
    "n = 5\n",
    "\n",
    "for i in range(n):\n",
    "    # create the file_name string in order to read in file\n",
    "    file_name = 'spotify_million_playlist_dataset/data/mpd.slice.' \\\n",
    "        + str(i*1000) \\\n",
    "        + '-' + str(i*1000+999) + '.json'\n",
    "\n",
    "    # Uncomment the following line to show progress\n",
    "    #print(file_name)\n",
    "\n",
    "    # open the file and store its contents in file_contents\n",
    "    with open(file_name) as user_file:\n",
    "        file_contents = user_file.read()\n",
    "\n",
    "    # we only care about the \"playlists\" part of this dictionary\n",
    "    # save the list of playlists in playlist_list\n",
    "    parsed_json = json.loads(file_contents)\n",
    "    playlist_list = parsed_json[\"playlists\"]\n",
    "\n",
    "\n",
    "    # create dataframe if it's first playlist, otherwise append info to existing dataframe\n",
    "    # the record_path argument tells the json_normalize function how to flatten the data\n",
    "    # the meta argument tells the json_nomralize function what meta data to keep\n",
    "    if i == 0:\n",
    "        data = pd.json_normalize(\n",
    "            playlist_list,\n",
    "            record_path=\"tracks\",\n",
    "            meta=[\"name\", \"collaborative\", \"pid\", \"num_followers\", \"num_edits\"]\n",
    "        )\n",
    "    else:\n",
    "        data = pd.concat(\n",
    "            [\n",
    "                data,\n",
    "                pd.json_normalize(\n",
    "                    playlist_list,\n",
    "                    record_path=\"tracks\",\n",
    "                    meta=[\"name\", \"collaborative\", \"pid\", \"num_followers\", \"num_edits\"]\n",
    "                )\n",
    "            ],\n",
    "            ignore_index = True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "348acc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=384\n",
    "\n",
    "t= AnnoyIndex(f, 'angular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "71cfd17e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.load('playlist_vectors.ann')\n",
    "t.get_n_items()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff38a38",
   "metadata": {},
   "source": [
    "# Searching example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "94823ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = 'tropical'\n",
    "\n",
    "#generate search vector\n",
    "#note that i am adding the suffix playlist to everything\n",
    "v_search = model.encode(search.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "a1642ae7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#will return the approximate nearest neighbors\n",
    "#pid's to the search vector\n",
    "#the order of this list is important: roughly ~ closest -> furthest \n",
    "num_neigh= 50\n",
    "pid_nns = t.get_nns_by_vector(v_search , num_neigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "a06232fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.drop_duplicates(subset = ['pid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "977e88cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tropical\n",
      "Tropical\n",
      "TROPICAL\n",
      "tropical\n",
      "Tropicales\n",
      "Tropics\n",
      "Cuba\n",
      "Tropicana\n",
      "Fiji\n",
      "Paradise\n",
      "VACATION\n",
      "Country summer\n",
      "country summer \n",
      "summer country\n",
      "Summer Country\n",
      "Summer country\n",
      "Summer Country\n",
      "Summer Country\n",
      "summer country\n",
      "summer country\n",
      "COSTA RICA \n",
      "Hawaiian\n",
      "Hawaii\n",
      "hawaii\n",
      "Hawaii \n",
      "HAWAII\n",
      "Island\n",
      "ISLAND\n",
      "Around the World\n",
      "Sky\n",
      "beach\n",
      "Beach\n",
      "beach\n",
      "Beach\n",
      "Beach\n",
      "thai\n",
      "Disneyland\n",
      "Florida\n",
      "Maui\n",
      "Panda\n",
      "panda\n",
      "Panda\n",
      "rainy days\n",
      "Rainy Days\n",
      "Rainy days\n",
      "Acústico\n",
      "Acústico \n",
      "Country\n",
      "Country\n",
      "Country\n"
     ]
    }
   ],
   "source": [
    "for pid in pid_nns:\n",
    "    name = list(df.loc[df['pid']== pid,'name'])[0]\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b62c30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
